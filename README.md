# DAinGD-lab5
# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #5 выполнил(а):
- Миронова Наталья Андреевна
- РИ-220930
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)


## Цель работы
познакомиться с программными средствами для создания системы машинного обучения и ее интеграции в Unity.

## Задание 1
### Найдите внутри C# скрипта “коэффициент корреляции ” и сделать выводы о том, как он влияет на обучение модели.
Ход работы: Проанализировала скрипт из Экономического скрипта и выявила следующий коэффициент корреляции. Он указывается в SetReward, при прямой зависимости или обратной
- ![Screenshot_26](https://github.com/knightalli/DAinGD-lab5/assets/127225486/36a4098a-c72d-41ab-8f79-c9af7e54621b)

## Задание 2
### Изменить параметры файла yaml-агента и определить какие параметры и как влияют на обучение модели. Привести описание не менее трех параметров.
Ход работы: Изучила параметры и их влияние на агента.
Описание следующих параметров: 
learning_rate: Скорость обучения - важный параметр для градиентного спуска. Он определяет, насколько сильно веса модели обновляются в направлении градиента.
learning_rate_schedule: Расписание скорости обучения. В данном случае используется линейное расписание, что означает линейное уменьшение скорости обучения от начального значения к конечному.
max_steps: Максимальное количество шагов обучения.
![Screenshot_25](https://github.com/knightalli/DAinGD-lab5/assets/127225486/cffbf6b8-fed3-4dd7-8dc2-c51cefc0e19d)



## Задание 3
### Приведите примеры, для каких игровых задачи и ситуаций могут использоваться примеры 1 и 2 с ML-Agent’ом. В каких случаях проще использовать ML-агент, а не писать программную реализацию решения?
- RollerBall подходит играм-гонкам, где AI-противникам нужно дойти до цели. Или игры, где AI-преследует персонажа-цель. Economics подходит для любой игры, где присутствуют шахты для добычи материалов. Например, защита замков.
- В задачах управления роботами или другими физическими сущностями, где применение точных математических моделей может быть трудно из-за сложной физики, ML-Agents могут обучаться на основе симуляций или реальных данных. Или где повышение сложности идет постепенно, Ml-Agentы позволяет равномерно повышать сложность уровней. 



## Выводы

ML-Agents представляет собой мощный инструмент для обучения агентов в среде, обладая своими преимуществами и ограничениями. Он автоматизирует процесс обучения, что существенно облегчает создание интеллектуальных поведений в играх. Однако, существуют определенные сложности, такие как необходимость правильной настройки параметров обучения, подбор оптимальных гиперпараметров, и не всегда гарантированное успешное обучение в сложных задачах.

В целом, ML-Agents предоставляет мощный инструментарий для интеграции искусственного интеллекта в игры, но успешное применение требует внимательного подхода к настройке и тщательного анализа результатов обучения.



| Plugin | README |
| ------ | ------ |
| Dropbox | [plugins/dropbox/README.md][PlDb] |
| GitHub | [plugins/github/README.md][PlGh] |
| Google Drive | [plugins/googledrive/README.md][PlGd] |
| OneDrive | [plugins/onedrive/README.md][PlOd] |
| Medium | [plugins/medium/README.md][PlMe] |
| Google Analytics | [plugins/googleanalytics/README.md][PlGa] |

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
